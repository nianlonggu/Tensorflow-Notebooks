{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow TPU in Google Colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nianlonggu/Tensorflow-Notebooks/blob/master/Tensorflow_TPU_in_Google_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9bd0Zy5SZGMz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# A simple tutorial of using Tensorflow TPU in Google Colab\n",
        "In this document, I provide a full example of how to use tensorfloe TPU in Colab. The common example of iris species recognition provided in [official turtorials](https://cloud.google.com/tpu/docs/tutorials/migrating-to-tpuestimator-api) contains many extra information, like dealing with the feature columns and manage the name of each dimension of the feature vector. This makes it sometimes misleading for the readers  to capture the key aspect of how to use TPU in their customized code. In this example, I modified the official document, and try to achieve the task of hand-written digit recognition in MNIST dataset.\n",
        "\n",
        "The main topics include: \n",
        "1. **tensorflow Dataset API**\n",
        "2. **tensorflow TPUEstimator API**\n",
        "3. **Google Cloud Storage**"
      ]
    },
    {
      "metadata": {
        "id": "t_wF_CiVcTll",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task Description\n",
        "Given an hand-written image, like: \n",
        "\n",
        "![MNIST](https://github.com/nianlonggu/Tensorflow-Notebooks/blob/master/figures/5.png?raw=true)\n",
        "\n",
        "the task is to train a CNN to correctly detect the number of the hand-written digit (5 in this case).  A typical way for training is to train the model using large number of ( **X**, **y** ) pairs, where **X** is the pixel matrix of an image and **y** is the corresponding label. This is a fully supervised training scheme.\n",
        "\n",
        "To use TPU tp achive this task, there are multiple ways. One is first design the model using keras, and then use the ** tf.contrib.tpu.keras_to_tpu_model** to cast the code to TPU specific code. Clike[ here ](https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/fashion_mnist.ipynb)to see the introduction.\n",
        "\n",
        "Another way is to design a customized TPUEstimator, and then run the train, evaluate and predict function. This method has a unified framework for general supervised training problems and is easier to tranfer over different computation platforms (CPU, GPU, TPU). This is also the main topic of this document.\n",
        "\n",
        "**Note**: before runing, clike in colab the \"Edit\"->\"Notebook Setting\" and choose TPU as accelerator!"
      ]
    },
    {
      "metadata": {
        "id": "G7u7Ffe1iWQx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Start of Coding"
      ]
    },
    {
      "metadata": {
        "id": "AXWiGxYqjZIp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### import python libraries"
      ]
    },
    {
      "metadata": {
        "id": "M-I2EXgTDknv",
        "colab_type": "code",
        "outputId": "baa8bfeb-b928-45ab-9972-7b7952884fdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras.datasets.mnist as mnist\n",
        "import math\n",
        "import os\n",
        "## plt is used to plot the results\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "OF0U1CV5mi9J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Different from keras_to_tpu_model, if we want use TPUEstimator in colab, the checkpoints files cannot be stored locally in colab. You will get an error like:\n",
        "\n",
        "***file system scheme '[local]' not implemented***\n",
        "\n",
        "As far as I know, the only choice is to store the ckpt files in **Google Cloud Storage**.  To solve this without any additional cost, you can visit https://cloud.google.com/storage/ , apply for a 1-year free trail accout, and activate the billing service. After this, following the website instruction to create a new Google cloud storage bucket with a name like \"awesome_gcs_bucket\". Then you get a address to acess the GCS: ** gs://awesome_gcs_bucket**  \n",
        "\n",
        "After get the GCS address, you need to authorize you google colab to get access to you Google Cloud Storage Busket using the following commands:"
      ]
    },
    {
      "metadata": {
        "id": "Y4Cp8KCMy3Mb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NH5_NWmzslGq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a Flag Class to hold all the global hyperparameters. \n",
        "This can also be achived by using tf.flags. Note that there are some bugs realated with tf.flags in Colab, simply add \"flags.DEFINE_string('f', '', 'kernel')\" to avoid it"
      ]
    },
    {
      "metadata": {
        "id": "RsoYNtDeuBvj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Flags:\n",
        "    def __init__(self):\n",
        "        ## tpu store the address of TPU, used to passed to the TPUClusterResolver\n",
        "        self.tpu = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "        ## model_dir specify the path to store the model parameters. Here we need to use the adress to the cloud storage bucket\n",
        "        ## model_dir will be passed to the tpu.RunConfig() function\n",
        "        self.model_dir = \"gs://awesome_gcs_bucket\"\n",
        "        \"\"\" batch_size: the batch size used for training, evaluation and prediction. It should be a multiple of the number of TPU cores.\n",
        "        Normally the number of TPU cores is 8, so the batch_size is usually 128. The reason for this is during TPU running, each batch of \n",
        "        data will be dispatched to each TPU cores, so the batch size should be divisable by the number of TPU cores.\"\"\"\n",
        "        self.batch_size = 128\n",
        "        \"\"\" train_steps define the number of steps of the total training procedure. In each step a batch of data a fed into the TPU for \n",
        "        computation. Note that in TPUEstimator train function there are two parameters: steps and max_steps. \n",
        "        \"steps\" means the further number of steps to be trained from now;\n",
        "        \"max_steps\" means the total maximum number of steps.\n",
        "        \"\"\"\n",
        "        self.train_steps = 10000\n",
        "        \"\"\"iterations_per_loop defines the number of train batches (steps) in TPU within one Session.run(), before returning to the CPU host\n",
        "        to prepare next group of train batches\n",
        "        \"\"\"\n",
        "        self.iterations_per_loop = 500\n",
        "        ## the bool flag for using tpu or not\n",
        "        self.use_tpu = True\n",
        "\n",
        "    \n",
        "#Create an entity of Class Flag, FLAGS is the global hyperparameter\n",
        "FLAGS = Flags()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fc08DtL5G-CZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Preprocessing Operation: load raw data and image plotting"
      ]
    },
    {
      "metadata": {
        "id": "40WWghkOD5bN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_mnist_data():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_eval = x_train[-5000:]/255.0\n",
        "    x_eval = np.expand_dims(x_eval, -1).astype(np.float32)  ## must convert float64 into np.float32 since the former is not supported by TPU!\n",
        "    y_eval = y_train[-5000:].astype(np.int32) ## convert to np.int32 which is recognized by TPU\n",
        "    x_train = x_train[ :-5000]/255.0\n",
        "    x_train = np.expand_dims(x_train, -1).astype(np.float32)\n",
        "    y_train = y_train[ :-5000].astype(np.int32)  ## by default y_train is not one-hot coded\n",
        "    x_test = x_test/255.0\n",
        "    x_test = np.expand_dims(x_test, -1).astype(np.float32)\n",
        "    y_test = y_test.astype(np.int32)\n",
        "  \n",
        "    return x_train, y_train, x_eval, y_eval, x_test, y_test\n",
        "\n",
        "\n",
        "## load the train/ eval and predict data\n",
        "x_train, y_train, x_eval, y_eval, x_test, y_test = load_mnist_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QOJ9YaI7KcDh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define the helper function for plotting images."
      ]
    },
    {
      "metadata": {
        "id": "nYo69jSGGFP9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_images( images, labels=None, preds= None  ):\n",
        "    images = np.squeeze(images )\n",
        "    num = images.shape[0]\n",
        "    n_rows = math.floor( math.sqrt( num ))\n",
        "    n_columns = math.ceil(math.sqrt(num))\n",
        "  \n",
        "    fig, axes = plt.subplots( n_rows, n_columns )\n",
        "  \n",
        "    if n_rows * n_columns == 1:\n",
        "        axes = [axes]\n",
        "    else:\n",
        "        axes = axes.flat\n",
        "  \n",
        "    for i, ax in enumerate( axes ):\n",
        "        if i < num:\n",
        "            ax.imshow( images[i] )\n",
        "            xlabel= \"\"\n",
        "        if labels is not None:\n",
        "            xlabel += \"True: %d \"%(labels[i])\n",
        "        if preds is not None:\n",
        "            xlabel += \"Pred: %d\"%(preds[i])\n",
        "        ax.set_xlabel(xlabel)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "411qovFhy-EF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the functions required by the TPUEstimator: input_functions and model_dunction\n",
        "The key part of using TPU is the TPUEstimator, this class contains the following main aspects:\n",
        "\n",
        "I. Parameters:\n",
        "1. model_fn:  \n",
        "The model_fn refers to a self-defined model function, this functions contains the contruction of network structure, as well as different operation for different value of the mode parameter.\n",
        "2. config:\n",
        "tpu.RunConfig() which contains the configuration of running: \n",
        "3. use_tpu:\n",
        "use TPU or not\n",
        "4. train/eval/predict_batch_size\n",
        "5. params:\n",
        "The model_fn is requred to have a parameter params which is a dict, apart from other defined key-value pair, params contains pre-defined \"batch_size\" key-value, this will be used to be allocated to the batch_size paramters of train/eval/predict_input_fn.\n",
        "\n",
        "II. Methods:\n",
        "1. train( input_fn ,  steps  )  # steps used to determine the number of batches from the start of training\n",
        "2. eval( input_fn, steps  )  # steps defines the number of batches from the start of evaluation, used to compute the overall evaluation metrics like accuracy, loss, etc.\n",
        "3. predict( input_fn )"
      ]
    },
    {
      "metadata": {
        "id": "1w0Oa0Nx15Xt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### The input function part:"
      ]
    },
    {
      "metadata": {
        "id": "jr9PECWWm0Eu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_input_fn( features, labels, batch_size ):\n",
        "    \"\"\"An input function for training\n",
        "    features: corresponding to x_train\n",
        "    labels: corresponding to y_train\n",
        "    batch_size: will be assigned by the reserved key-value pair params[\"batch_size\"]\n",
        "    \"\"\"\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "    # Shuffle, repeat.\n",
        "    dataset = dataset.shuffle(1000).repeat() # repeat without parameters means get random batches from training dataset within unlimited times\n",
        "    # TPU specific batch the slices, to make sure that the batch size of each acquired batch is divisible by the number of TPU cores\n",
        "    dataset = dataset.batch( batch_size, drop_remainder = True )\n",
        "    # Return the dataset.\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G7gKO1E5Q-N3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def eval_input_fn(features, labels, batch_size):\n",
        "    \"\"\"An input function for training\"\"\"\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "    # 1000 is the buffer size for shuffling\n",
        "    dataset = dataset.shuffle(1000).repeat()\n",
        "    dataset = dataset.batch(batch_size, drop_remainder = True )\n",
        "    # Return the dataset.\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q6pCeeWMTBp7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_input_fn(features, labels,batch_size):\n",
        "    \"\"\"An input function for training\"\"\"\n",
        "    # Convert the inputs to a Dataset.\n",
        "    # For predict use_tpu should be False, since drop_remainder is False\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "    # for prediction, shuffle() and repeat() is not needed, since all data will be predicted\n",
        "    # for prediction, since no need to guarantee the high performance of TPU, so no need to set drop_remainder= True\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    # Return the dataset.\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qoupeiiFo1_N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def metric_fn(labels, logits):\n",
        "    \"\"\"Function to return metrics for evaluation.\n",
        "    The input parameters can be arbritary\n",
        "    \"\"\"\n",
        "    predicted_classes = tf.argmax(logits, 1)\n",
        "    accuracy = tf.metrics.accuracy(labels=labels, predictions=predicted_classes)\n",
        "    \n",
        "    return {\"accuracy\": accuracy}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HiewctTEVQsf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### The model_fn part"
      ]
    },
    {
      "metadata": {
        "id": "TDnPK26tVW-N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def model_fn(features, labels, mode, params):\n",
        "    # Args:\n",
        "    # features: This is the x-arg from the input_fn.\n",
        "    # labels:   This is the y-arg from the input_fn,\n",
        "    #           see e.g. train_input_fn for these two.\n",
        "    # mode:     Either TRAIN, EVAL, or PREDICT\n",
        "    # params:   User-defined hyper-parameters, e.g. learning-rate.\n",
        "    \n",
        "\n",
        "    \"\"\" Part I. create the model networks\"\"\"\n",
        "    x = features\n",
        "    # First convolutional layer.\n",
        "    net = tf.layers.conv2d(inputs=x, name='layer_conv1',filters=32, kernel_size=5,\n",
        "                           padding='same', strides = 2 ,activation=tf.nn.relu)\n",
        "    # Second convolutional layer.\n",
        "    net = tf.layers.conv2d(inputs=net, name='layer_conv2', filters=64, kernel_size=5,\n",
        "                           padding='same', strides =2 ,activation=tf.nn.relu)   \n",
        "   \n",
        "    net = tf.contrib.layers.flatten(net)\n",
        "    net = tf.layers.dense(inputs=net, name='layer_fc1', units=128, activation=tf.nn.relu)    \n",
        "    logits = tf.layers.dense(inputs=net, name='layer_fc2',units=10)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \"\"\"Part II. define the loss and relative parameters for mode == TRAIN/EVAL/PREDICT\"\"\"\n",
        "    ## compute loss\n",
        "    loss =  tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
        "    # Softmax output of the neural network.\n",
        "    y_pred_probabilities = tf.nn.softmax(logits=logits)\n",
        "    # Classification output of the neural network.\n",
        "    y_pred_classes = tf.argmax(y_pred_probabilities, axis=1)\n",
        "\n",
        "\n",
        "    \n",
        "    ## operations for the training mode, define the optimizer, and reconfig it using tpu.CrossShardOptimizer\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        # Define the optimizer\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=params[\"learning_rate\"])\n",
        "        if FLAGS.use_tpu:\n",
        "            optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n",
        "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
        "\n",
        "        spec= tf.contrib.tpu.TPUEstimatorSpec(mode=mode, loss=loss,train_op= train_op  )\n",
        "    ## for EVAL mode, the parameters eval_metrics takes a tuple or list of two elements. The first element is a callable function,\n",
        "    ## The second element is a list of parameters. The return value of the callable function will be shown in the evaluatio results\n",
        "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "        spec = tf.contrib.tpu.TPUEstimatorSpec(mode=mode, loss=loss, eval_metrics=(metric_fn, [labels, logits] ) )\n",
        "\n",
        "    ## operations for PREDICT:  given the input images, return a dict which contains the reqired information (predicted y label)\n",
        "    elif mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        predictions = {\n",
        "              \"true_class\":  labels ,\n",
        "              \"pred_class\":  y_pred_classes,\n",
        "              \"probability\": y_pred_probabilities,\n",
        "        }\n",
        "        spec = tf.contrib.tpu.TPUEstimatorSpec(mode=mode, predictions=predictions)\n",
        "\n",
        "        \n",
        "    return spec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9WoEKTM3WhvY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create the TPUEstimator entity, and run the train / evaluate/ predict"
      ]
    },
    {
      "metadata": {
        "id": "ovokb2YRWPG8",
        "colab_type": "code",
        "outputId": "6868bc66-4771-4b67-e451-0ac884a398db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "cell_type": "code",
      "source": [
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    model_dir=FLAGS.model_dir,\n",
        "    cluster=tf.contrib.cluster_resolver.TPUClusterResolver(FLAGS.tpu),\n",
        "    session_config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True),\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(FLAGS.iterations_per_loop),\n",
        "    )\n",
        "\n",
        "model = tf.contrib.tpu.TPUEstimator(\n",
        "                               model_fn=model_fn,\n",
        "                               params = {\"learning_rate\": 1e-4 },\n",
        "                               config = run_config,\n",
        "                               use_tpu= FLAGS.use_tpu,\n",
        "                               train_batch_size=FLAGS.batch_size,\n",
        "                               eval_batch_size=FLAGS.batch_size,\n",
        "                               predict_batch_size=FLAGS.batch_size,\n",
        "                              )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://awesome_gcs_bucket', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "log_device_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.26.247.138:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5fc73d4d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.26.247.138:8470', '_evaluation_master': 'grpc://10.26.247.138:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=500, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f5fcd377320>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "odBUseLSWYtl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training"
      ]
    },
    {
      "metadata": {
        "id": "t8dY5URVWa5x",
        "colab_type": "code",
        "outputId": "c0bc592a-1ae2-4082-f47f-a6ee96a32e4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3007
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\" lambda is an anonymous function which has a parameter params, this params is further passed to the batch_size parameter of train_input_fn\n",
        "The reason for this setting is in TPUEstimator the input_fn is required to have only one parameter \"params\", so the model_fn params can be passed\n",
        "to the input_fn to control the batch_size on live. Using lambda function encapsulate the train_input_fn into a function with only one parameter params\n",
        "\"\"\"\n",
        "## steps= 10000 means 10000 batchs is fed into the TPU. With a batch_size = 128, it accounts for 1280000 samples. For MNIST data the number\n",
        "## of train samples are around 60000, 10000 steps means 1280000/60000 = 21 epochs\n",
        "model.train( input_fn = lambda params: train_input_fn( x_train, y_train, params[\"batch_size\"] ), steps=10000  )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.26.247.138:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 3268548067848416981)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 16597060784137536254)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 8135305259230580745)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 16537533837436394017)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 16383102542737394051)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 13141973026281168128)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 11079610526211105842)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 5645528005719777997)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 10904523937364832109)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 10846521158165584020)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 14222551037478600437)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From <ipython-input-10-95a416209557>:15: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv2d instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-10-95a416209557>:21: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from gs://awesome_gcs_bucket/model.ckpt-10000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 10000 into gs://awesome_gcs_bucket/model.ckpt.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 7 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0021340451, step = 10500\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.006995136, step = 11000 (0.560 sec)\n",
            "INFO:tensorflow:global_step/sec: 897.284\n",
            "INFO:tensorflow:examples/sec: 114852\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0030175862, step = 11500 (0.534 sec)\n",
            "INFO:tensorflow:global_step/sec: 936.91\n",
            "INFO:tensorflow:examples/sec: 119924\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.006688567, step = 12000 (0.555 sec)\n",
            "INFO:tensorflow:global_step/sec: 899.901\n",
            "INFO:tensorflow:examples/sec: 115187\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.027816031, step = 12500 (0.556 sec)\n",
            "INFO:tensorflow:global_step/sec: 900.282\n",
            "INFO:tensorflow:examples/sec: 115236\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.1450661, step = 13000 (0.537 sec)\n",
            "INFO:tensorflow:global_step/sec: 930.933\n",
            "INFO:tensorflow:examples/sec: 119159\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0060674497, step = 13500 (0.552 sec)\n",
            "INFO:tensorflow:global_step/sec: 905.005\n",
            "INFO:tensorflow:examples/sec: 115841\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00016194367, step = 14000 (0.554 sec)\n",
            "INFO:tensorflow:global_step/sec: 901.708\n",
            "INFO:tensorflow:examples/sec: 115419\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00049425894, step = 14500 (0.563 sec)\n",
            "INFO:tensorflow:global_step/sec: 886.234\n",
            "INFO:tensorflow:examples/sec: 113438\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00033608818, step = 15000 (0.545 sec)\n",
            "INFO:tensorflow:global_step/sec: 921.061\n",
            "INFO:tensorflow:examples/sec: 117896\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00014658815, step = 15500 (0.587 sec)\n",
            "INFO:tensorflow:global_step/sec: 851.45\n",
            "INFO:tensorflow:examples/sec: 108986\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0041570025, step = 16000 (0.570 sec)\n",
            "INFO:tensorflow:global_step/sec: 877.566\n",
            "INFO:tensorflow:examples/sec: 112328\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 4.999934e-05, step = 16500 (0.572 sec)\n",
            "INFO:tensorflow:global_step/sec: 873.761\n",
            "INFO:tensorflow:examples/sec: 111841\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 3.8110356e-05, step = 17000 (0.555 sec)\n",
            "INFO:tensorflow:global_step/sec: 901.053\n",
            "INFO:tensorflow:examples/sec: 115335\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00073732313, step = 17500 (0.537 sec)\n",
            "INFO:tensorflow:global_step/sec: 930.556\n",
            "INFO:tensorflow:examples/sec: 119111\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.004777601, step = 18000 (0.556 sec)\n",
            "INFO:tensorflow:global_step/sec: 899.921\n",
            "INFO:tensorflow:examples/sec: 115190\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00079086976, step = 18500 (0.565 sec)\n",
            "INFO:tensorflow:global_step/sec: 884.819\n",
            "INFO:tensorflow:examples/sec: 113257\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.00063321966, step = 19000 (0.560 sec)\n",
            "INFO:tensorflow:global_step/sec: 892.965\n",
            "INFO:tensorflow:examples/sec: 114299\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.03678082, step = 19500 (0.568 sec)\n",
            "INFO:tensorflow:global_step/sec: 881.684\n",
            "INFO:tensorflow:examples/sec: 112856\n",
            "INFO:tensorflow:Enqueue next (500) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (500) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 4.8602014e-05, step = 20000 (0.577 sec)\n",
            "INFO:tensorflow:global_step/sec: 865.774\n",
            "INFO:tensorflow:examples/sec: 110819\n",
            "INFO:tensorflow:Saving checkpoints for 20000 into gs://awesome_gcs_bucket/model.ckpt.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Loss for final step: 4.8602014e-05.\n",
            "INFO:tensorflow:training_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.contrib.tpu.python.tpu.tpu_estimator.TPUEstimator at 0x7f5fc73d4cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "gsvWROSqg_Hc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ]
    },
    {
      "metadata": {
        "id": "2-TdmDsUtAN8",
        "colab_type": "code",
        "outputId": "8216b022-3c25-4561-c780-674f440c1eaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        }
      },
      "cell_type": "code",
      "source": [
        "eval_result = model.evaluate(input_fn=lambda params: eval_input_fn( x_eval, y_eval, params[\"batch_size\"]), steps = 10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py:2655: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-04-09T10:27:47Z\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://awesome_gcs_bucket/model.ckpt-20000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 9 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Enqueue next (10) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (10) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Evaluation [10/10]\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Finished evaluation at 2019-04-09-10:28:00\n",
            "INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.9890625, global_step = 20000, loss = 0.024039526\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: gs://awesome_gcs_bucket/model.ckpt-20000\n",
            "INFO:tensorflow:evaluation_loop marked as finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WnbsEWaHgn99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1663def2-ac6a-449a-b816-948f80c0b8d6"
      },
      "cell_type": "code",
      "source": [
        "eval_result"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.9890625, 'global_step': 20000, 'loss': 0.024039526}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "PFd5J_9HhJN8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Predict"
      ]
    },
    {
      "metadata": {
        "id": "oo_STluG0nVU",
        "colab_type": "code",
        "outputId": "48f3da80-cef7-4003-b884-f05894bba036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1028
        }
      },
      "cell_type": "code",
      "source": [
        "predict_result = model.predict(input_fn=lambda params: predict_input_fn(x_test[0:9],y_test[0:9], params[\"batch_size\"]))\n",
        "\n",
        "images = []\n",
        "true_classes =[]\n",
        "pred_classes =[]\n",
        "\n",
        "for pred_dict, image, true_class in zip( predict_result, x_test, y_test  ):\n",
        "    pred_class = pred_dict[\"pred_class\"]\n",
        "    pred_prob = pred_dict[\"probability\"][pred_class]\n",
        "    print( \"Prediction is %d, probility %.1f, expected %d\" %( pred_class, pred_prob, true_class )  )\n",
        "    images.append(image)\n",
        "    true_classes.append( true_class )\n",
        "    pred_classes.append( pred_class )\n",
        "\n",
        "plot_images( np.asarray(images), np.asarray(true_classes), np.asarray( pred_classes )  )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://awesome_gcs_bucket/model.ckpt-20000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 13 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "Prediction is 7, probility 1.0, expected 7\n",
            "Prediction is 2, probility 1.0, expected 2\n",
            "Prediction is 1, probility 1.0, expected 1\n",
            "Prediction is 0, probility 1.0, expected 0\n",
            "Prediction is 4, probility 1.0, expected 4\n",
            "Prediction is 1, probility 1.0, expected 1\n",
            "Prediction is 4, probility 1.0, expected 4\n",
            "Prediction is 9, probility 1.0, expected 9\n",
            "Prediction is 5, probility 1.0, expected 5\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAFHCAYAAAAItfNdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnWkByi6UpQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "oI1-XlO2oG-c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is a complete procedure of using TPU in Colab. In the further, runing more complicated model like GAN on TPU will be tried. Hope this may help."
      ]
    }
  ]
}